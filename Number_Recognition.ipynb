{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNND2ZvWEb6Abadiv/hiG94",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sukhpreet2001/Bharat-Intern-Oct-2023/blob/main/Number_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wpnu0xLvJPKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61797072-2e1a-4c3f-cf6e-502036875809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 27s 34ms/step - loss: 0.2184 - accuracy: 0.9319 - val_loss: 0.0852 - val_accuracy: 0.9736\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0493 - val_accuracy: 0.9863\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 0.0474 - val_accuracy: 0.9862\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0310 - accuracy: 0.9907 - val_loss: 0.0414 - val_accuracy: 0.9883\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.0364 - val_accuracy: 0.9891\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0285 - accuracy: 0.9900\n",
            "Test accuracy: 0.9900000095367432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Combined cell with all code\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from google.colab import files\n",
        "\n",
        "# data_preprocessing.py\n",
        "def load_and_preprocess_data():\n",
        "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "    train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "    train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "    test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "    train_labels = to_categorical(train_labels)\n",
        "    test_labels = to_categorical(test_labels)\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "# model.py\n",
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "# train_model.py\n",
        "def train_model(model, train_images, train_labels, epochs=5, batch_size=64, validation_split=0.2):\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
        "\n",
        "# evaluate_model.py\n",
        "def evaluate_model(model, test_images, test_labels):\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "    print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# main.py\n",
        "def main():\n",
        "    train_images, train_labels, test_images, test_labels = load_and_preprocess_data()\n",
        "    model = build_model()\n",
        "    train_model(model, train_images, train_labels)\n",
        "    evaluate_model(model, test_images, test_labels)\n",
        "    model.save('digit_recognition_model.h5')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}